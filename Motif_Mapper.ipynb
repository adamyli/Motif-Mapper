{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Motif Mapper",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "xPIALRTCsUvm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns; sns.set()\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gpbLBM-k0Uiv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Regulatory Motifs & Hidden Messages in DNA"
      ]
    },
    {
      "metadata": {
        "id": "hT3fQ-0D0bPk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Coming fresh off our OriCalculator project, we saw the benefits of finding frequent strands and narrowing down windows for OriC. However towards the end we saw the weakness of our algorithm if a strand had a mutation or slight mismatch with our original, we would have a tough time finding it. This is where motif finding comes in. \n",
        "This is helpful in situations where you worry you may have mutated the subject in an experiment or conversely, implanting a mismatched motif into a strand that you now want to locate. It is also important because some motifs are responsible for certain actions in an organism, from awakening dormant TB spores to clock genes that control your circadian clock. Finding these can be imperative in different fields.\n",
        "\n",
        "\n",
        "We'd love it if these motifs were conserved but depending on position, they can bind to a slightly mismatched string, and we want to find these to make sense of them.\n",
        "\n",
        "Much like the OriCalculator, it should be noted that many of these algorithms could be streamlined with the use of numeric processing libraries like numpy/tensorflow and data manipulation ones like pandas. However to focus on teaching basic python fundamentals and not overwhelm you, we'll focus on purely what Python can offer."
      ]
    },
    {
      "metadata": {
        "id": "oncMGsEjwfki",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_genome = 'ATCAATGATCAACGTAAGCTTCTAAGCATGATCAAGGTGCTCACACAGTTTATCCACAACCTGAGTGGATGACATCAAGATAGGTCGTTGTATCTCCTTCCTCTCGTACTCTCATGACCACGGAAAGATGATCAAGAGAGGATGATTTCTTGGCCATATCGCAATGAATACTTGTGACTTGTGCTTCCAATTGACATCTTCAGCGCCATATTGCGCTGGCCAAGGTGACGGAGCGGGATTACGAAAGCATGATCATGGCTGTTGTTCTGTTTATCTTGTTTTGACTGAGACTTGTTAGGATAGACGGTTTTTCATCACTGACTAGCCAAAGCCTTACTCTGCCTGACATCGACCGTAAATTGATAATGAATTTACATGCTTCCGCGACGATTTACCTCTTGATCATCGATCCGATTGAAGATCTTCAATTGTTAATTCTCTTGCCTCGACTCATAGCCATGATGAGCTCTTGATCATGTTTCCTTAACCCTCTATTTTTTACGGAAGAATGATCAAGCTGCTGCTCTTGATCATCGTTTC'\n",
        "sample_dna_list = ['TCGGG', 'CCGGT', 'ACGGG', 'TTGGG']\n",
        "#Arbitrary string and list for us to test our functions/pipeline on."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I-rstRIBLZP7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DNA Sequence Manipulation and Matrices Creation"
      ]
    },
    {
      "metadata": {
        "id": "IRq8iAQozuW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nuc_counter(Motifs):\n",
        "  '''\n",
        "  \n",
        "  Input: A list of DNA strands\n",
        "  \n",
        "  Output: A matrix containing the sum of occurrences of a nucleotide of each strand at every position. (See below for example explanation)\n",
        "  \n",
        "  '''\n",
        "  count = {}\n",
        "  kmer_len = len(Motifs[0])\n",
        "  for letter in \"ACGT\":\n",
        "      count[letter] = []\n",
        "      for j in range(kmer_len):\n",
        "          count[letter].append(1)\n",
        "  for i in range(len(Motifs)):\n",
        "      for j in range(kmer_len):\n",
        "          symbol = Motifs[i][j]\n",
        "          count[symbol][j] += 1 \n",
        "  return count\n",
        "  \n",
        "  \n",
        "def nuc_counter_profile(Motifs):\n",
        "  '''\n",
        "  \n",
        "  Input: A list of DNA strands\n",
        "  \n",
        "  Output: A matrix containing the sum of occurrences of a nucleotide of each strand at every position divided by number of DNA strands. (See below for example explanation)\n",
        "  \n",
        "  '''\n",
        "  profile = {}\n",
        "  kmer_len = len(Motifs[0])\n",
        "  for letter in \"ACGT\":\n",
        "      profile[letter] = []\n",
        "      for j in range(kmer_len):\n",
        "          profile[letter].append(1)\n",
        "  for i in range(len(Motifs)):\n",
        "      for j in range(kmer_len):\n",
        "          symbol = Motifs[i][j]\n",
        "          profile[symbol][j] += 1\n",
        "  for letter in \"ACGT\":\n",
        "      for position in range(kmer_len):\n",
        "          profile[letter][position] = profile[letter][position]/(len(Motifs)+4)\n",
        "  return profile\n",
        "\n",
        "\n",
        "def consensus_string(Motifs):\n",
        "  '''\n",
        "  \n",
        "  Input: A list of DNA strands\n",
        "  Output: The string comprised of the most frequent nucleotides at each position. (See below for example explanation)\n",
        "  \n",
        "  '''\n",
        "\n",
        "  count = nuc_counter(Motifs)\n",
        "  consensus = \"\"\n",
        "  for i in range(len(Motifs[0])):\n",
        "      cur_max = 0\n",
        "      frequentletter = \"\"\n",
        "      for letter in \"ACGT\":\n",
        "          if count[letter][i] >= cur_max:\n",
        "              cur_max = count[letter][i]\n",
        "              frequentletter = letter\n",
        "      consensus += frequentletter\n",
        "  return consensus\n",
        " \n",
        "  \n",
        "def motif_scoring(Motifs):\n",
        "  '''\n",
        "  \n",
        "  Input: A list of DNA strands\n",
        "  Output: The string comprised of the most frequent nucleotides at each position. (See below for example explanation)\n",
        "  \n",
        "  '''\n",
        "  score = 0\n",
        "  consensus = consensus_string(Motifs)\n",
        "  for i in range(len(Motifs)):\n",
        "      score += HammingDistance(Motifs[i], consensus)\n",
        "  return score \n",
        "\n",
        "  \n",
        "def HammingDistance(p, q):\n",
        "  '''\n",
        "  Simple formula to calculate how many mismatches there ar between two strings (p and q)\n",
        "  '''\n",
        "  count = 0\n",
        "  for i in range(len(p)):\n",
        "      if p[i] != q[i]:\n",
        "          count += 1\n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2-MiGwb2OhLK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Given a set of DNA strings. We apply the above functions in a certain way to gain insight on them. They are general useful functions for changing motif data. For example given the following strings:\n",
        "\n",
        "T C G G G\n",
        "\n",
        "C C G G T\n",
        "\n",
        "A C G G G\n",
        "\n",
        "T T G G G\n",
        "\n",
        "We turn these into a matrix. And these are what we will call our motifs.\n",
        "Let's apply our functions on them. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "q-1huuzPM8-M",
        "colab_type": "code",
        "outputId": "e54684f0-3466-4036-ae1a-0f4a282f5da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "print(nuc_counter(sample_dna_list))\n",
        "print(nuc_counter_profile(sample_dna_list))\n",
        "print(consensus_string(sample_dna_list))\n",
        "print(motif_scoring(sample_dna_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'A': [2, 1, 1, 1, 1], 'C': [2, 4, 1, 1, 1], 'G': [1, 1, 5, 5, 4], 'T': [3, 2, 1, 1, 2]}\n",
            "{'A': [0.25, 0.125, 0.125, 0.125, 0.125], 'C': [0.25, 0.5, 0.125, 0.125, 0.125], 'G': [0.125, 0.125, 0.625, 0.625, 0.5], 'T': [0.375, 0.25, 0.125, 0.125, 0.25]}\n",
            "TCGGG\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tDKxEc3GJxM3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So let's examine what happens. The following is our motif matrix of intial DNA strands. \n",
        "\n",
        "\n",
        "T C G G G (Motifs)\n",
        "\n",
        "C C G G T\n",
        "\n",
        "A C G G G\n",
        "\n",
        "T T G G G\n",
        "_____________________\n",
        "This consensus is the most frequent nucleotide in each column.\n",
        "\n",
        "T C G G G (Consensus)\n",
        "_____________________\n",
        "The score is the amount of nucleotides that do not match the most frequent one. We usually want to minimize this score to get the most 'conserved' kmer.\n",
        "\n",
        "2+1+0+0+1 = 4 (Score)\n",
        "\n",
        "_____________________\n",
        "The count matrix depicts how often each nucleotide occurs in each column. *Notice that there is a '1' added where there should be a zero. This is to avoid an entire string's probability being equaled to 0 even when sometimes the rest of its string may only differ by 1 spot.*\n",
        "\n",
        "\n",
        "A: [2, 1, 1, 1, 1] (Motif Counts)\n",
        "\n",
        "C: [2, 4, 1, 1, 1]\n",
        "\n",
        "G: [1, 1, 5, 5, 4]\n",
        "\n",
        "T': [3, 2, 1, 1, 2]\n",
        "_____________________\n",
        "The profile matrix divides each count by the number of nucleotides in each column, to give you a probability of 'generating' that nucleotide.\n",
        "\n",
        "\n",
        "A: [0.25, 0.125, 0.125, 0.125, 0.125] (Motif Profile)\n",
        "\n",
        "C: [0.25, 0.5, 0.125, 0.125, 0.125]\n",
        "\n",
        "G: [0.125, 0.125, 0.625, 0.625, 0.5]\n",
        "\n",
        "T: [0.375, 0.25, 0.125, 0.125, 0.25]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2agq7vK9yEZt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Greedy algorithms in Motif Finding"
      ]
    },
    {
      "metadata": {
        "id": "ANPaeqEobqZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Pr(Kmer, profile):\n",
        "  \n",
        "  '''\n",
        "  Input: A specific kmer strand and a pre-calculated profile matrix of probabilities.\n",
        "  \n",
        "  Output: The probability of getting that specific kmer based off the matrix.\n",
        "  '''\n",
        "  \n",
        "  p = 1\n",
        "  for i in range(len(Kmer)):\n",
        "      p = p * profile[Kmer[i]][i]\n",
        "  return p\n",
        "\n",
        "  \n",
        "def kmer_with_max_probability(sample_genome, t, profile):\n",
        "  \n",
        "  '''\n",
        "  Input: A sample string, k for length of kmer you want to find, and a profile matrix of probabilities you are searching through.\n",
        "  Output: Most probable kmer in a string (from the probabilities of a previously generated profile matrix)\n",
        "  \n",
        "  \n",
        "  So for an example text/genome such as ACCGGTTGT, every possible say 3mer like ACC, CCG,CGG  etc. is evaluated vs the profile\n",
        "  Profile being a 4xK(3 in this case) e.g: A: 0.3 0.4 0.2\n",
        "                                           C: 0.2 0.2 0.3\n",
        "                                           G: 0.4 0.3 0.1\n",
        "                                           T: 0.3 0.3 0.5\n",
        "  Probability is calculated (ACC = 0.3 * 0.2 * 0.3 for example)\n",
        "  Max probability is recorded, along with its 3mer.\n",
        "  And thus, the most probable 3mer in this specific profile i.e a 3 mer that was \n",
        "  most likely to be generated by a Profile among all Kmers in 'text'\n",
        "                                           \n",
        "  '''\n",
        "  max_pr = -1\n",
        "  for i in  range(len(sample_genome) -  t+1):\n",
        "    kmer = sample_genome[i:i+t]\n",
        "    current_pr = Pr(kmer, profile)\n",
        "    if current_pr > max_pr:\n",
        "      max_pr = current_pr\n",
        "      max_pr_kmer = kmer\n",
        "\n",
        "  return max_pr_kmer\n",
        "\n",
        "\n",
        "def GreedyMotifSearch(Dna, k):\n",
        "  \n",
        "  \"\"\"\n",
        "  A culmination of all our functions so far. Given a DNA set of strings, we want to find a set of motifs that match each ohter\n",
        "  closely. \n",
        "  To start with an input of example set of DNA strings, k = 3 and number of strings = 5:\n",
        "  \n",
        "  ACCGGTTGT\n",
        "  GCTAGGTAC\n",
        "  CCTAGTACG\n",
        "  ACAACTTGT\n",
        "  ATTACCTGT\n",
        "  \n",
        "  We take the first 3mers of each string as a basis to begin comparing future motifs against. So [ACC, GCT, CCT, ACA, ATT].\n",
        "  We have an empty string named Motifs we want to begin using as our Profile matrix. We will be iterating through each kmer in\n",
        "  every strand. Lets start with the first strand 'ACCGGTTGT'. Its first kmer is ACC which we add to Motifs.\n",
        "  Now we our Profile function takes the profile of our Motifs string (which currently contains only ACC) and is inputed into \n",
        "  our function kmer_with_max_probability along with the next DNA string (GCTAGGTAC) with k = 3. \n",
        "  Remember this function iterates through GCTAGGTAC with a k length sliding window and returns the kmer with the highest prob \n",
        "  to be generated. For the sake of explanation we'll say the result is XYZ. This gets added to our Motifs list which is now\n",
        "  [ACC, XYZ]. Now this gets repeated for all strings, and now the next iteration, our Profile(Motifs[0:j]) will have 2 motifs to\n",
        "  create a profile out of.\n",
        "  At the end of each iteration it checks the score of the current 'Motifs' list and compares it to our original Best Motifs and\n",
        "  replaces it if its lower (because we want to minimize our score and find a more conservative strand).\n",
        "  \"\"\" \n",
        "  \n",
        "  best_score_motifs = []\n",
        "  for i in range(len(Dna)):\n",
        "      best_score_motifs.append(Dna[i][0:k])\n",
        "  n = len(Dna[0])\n",
        "  for i in range(n-k+1):\n",
        "      Motifs = []\n",
        "      Motifs.append(Dna[0][i:i+k])\n",
        "      for j in range(1, len(Dna)):\n",
        "          P = nuc_counter_profile(Motifs[0:j])\n",
        "          Motifs.append(kmer_with_max_probability(Dna[j], k, P))\n",
        "      if motif_scoring(Motifs) < motif_scoring(best_score_motifs):\n",
        "          best_score_motifs = Motifs\n",
        "  return best_score_motifs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T8ZNwBvBnBKv",
        "colab_type": "code",
        "outputId": "9bf84af9-9aad-4955-e9e5-190ab5f7dcf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "print(Pr('TCGGG', nuc_counter_profile(sample_dna_list)))\n",
        "print(kmer_with_max_probability(sample_genome, 3, nuc_counter_profile(sample_dna_list)))\n",
        "print(GreedyMotifSearch(sample_dna_list, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.03662109375\n",
            "TCG\n",
            "['CGG', 'CGG', 'CGG', 'TGG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vmVyYWkXLW1D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Greedy algorithms traditionally in computer science fields are algorithms that try to find the 'best' or most optimal choice at every stage and iteration. Hence the name 'greedy'. Often times its synonomous with a brute force method as it involves looking at *every* option to decide if its better than the rest.\n",
        "This greedy algorithm looks at every string and takes the kmer with the highest probability kmer (and therefore the most conserved) using what is at first a profile generated from a random kmer. However, with each addition of a new kmer to the motif matrix, it gets closer to a more conservative matrix."
      ]
    },
    {
      "metadata": {
        "id": "q6knYZB3Lfy1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Gibbs Random Sampling & Monte Carlo Methods"
      ]
    },
    {
      "metadata": {
        "id": "7A9MjgIlLhlo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Normalize(Probabilities):\n",
        "    '''\n",
        "    Input = Probability dictionary\n",
        "    Output = Dicitionary of normalized probabilities\n",
        "    Divides every value in Probabilities by sum of all values in Probabilities. Handy probability tool to have.\n",
        "    '''\n",
        "    \n",
        "    sum = 0\n",
        "    for i in Probabilities.values():\n",
        "        sum += i\n",
        "    for j in Probabilities.keys():\n",
        "        Probabilities[j] = Probabilities[j] / sum \n",
        "    return Probabilities\n",
        "\n",
        "\n",
        "def motif_creation_double_matrix(Profile, Dna):\n",
        "  '''\n",
        "  Input: A pre-calculated profile matrix and a pre-calculated set of DNA strings\n",
        "  Output: Motifs created via the'kmer_with_max_probability' function. Each one is made from one of the DNA strings via kmer_with_max_probability\n",
        "  \n",
        "  '''  \n",
        "  k = len(Profile)\n",
        "  return [kmer_with_max_probability(string, k, Profile) for string in Dna]\n",
        "\n",
        "  \n",
        "def rand_motif_from_DNAset(Dna, k):\n",
        "  '''\n",
        "  Input: Set of DNA strings and k describing length of kmer\n",
        "  Ouput: List of kmers that are random selected from each one of the DNA strings\n",
        "  \n",
        "  '''\n",
        "  random_kmers = []\n",
        "  for i in range(len(Dna)):\n",
        "      starter_number =  random.randint(0, len(Dna[0])-k)\n",
        "      kmer = Dna[i][starter_number:starter_number+k]\n",
        "      random_kmers.append(kmer)    \n",
        "  return random_kmers\n",
        "  \n",
        "  \n",
        "def random_greedy_algorithm(Dna, k):\n",
        "  '''\n",
        "  Input: Set of DNA strings and k describing length of kmer\n",
        "  Output: The best scored motifs from the DNA strand\n",
        "  \n",
        "  Some similarities with our greedy algorithm. If we were to take for example the following set of DNA strings and k = 3 as input:\n",
        "  ACCGGT\n",
        "  GCTAGC\n",
        "  CCTAGA\n",
        "  \n",
        "  We would take a random 3mer from each row with our random motif function so that we have for example:\n",
        "  CCG\n",
        "  AGC\n",
        "  TAG\n",
        "  \n",
        "  We then create a profile matrix out of this. Now we have our original Dna input and a profile matrix. We can use our motif creation function again!\n",
        "  Then we score the new one vs the old one.\n",
        "  The key point here is that you can iterate over and over and over as much as you like given a DNA set of strings to gradually converge to the best scores.\n",
        "  \n",
        "  '''\n",
        "  cur = rand_motif_from_DNAset(Dna, k)\n",
        "  best_score_motifs = cur\n",
        "  while True:\n",
        "    Profile = nuc_counter_profile(cur)\n",
        "    cur = motif_creation_double_matrix(Profile, Dna)\n",
        "    if motif_scoring(cur) < motif_scoring(best_score_motifs):\n",
        "      best_score_motifs = cur\n",
        "    else:\n",
        "      return best_score_motifs \n",
        "    \n",
        "def random_outcome_generator(Probabilities):\n",
        "    total = float(sum(Probabilities))\n",
        "    r = random.random()\n",
        "    partialSum = 0.0\n",
        "    for i in range(len(Probabilities)):\n",
        "        partialSum += Probabilities[i]\n",
        "        if partialSum/total >= r:\n",
        "            return i\n",
        "    return -1\n",
        "    \n",
        "        \n",
        "def random_dice(Probabilities):\n",
        "  '''\n",
        "  \n",
        "  Input: A set of probabilities\n",
        "  Output: Random outcome\n",
        "  \n",
        "  Essential a i-sided die where i is the number of possibilities there are. Useful for generating a random outcome.\n",
        "  \n",
        "  '''\n",
        "  random_roll = random.uniform(0, 1)\n",
        "  for key in Probabilities:\n",
        "      random_roll -= Probabilities[key]\n",
        "      if random_roll <= 0:\n",
        "        return key\n",
        "\n",
        "        \n",
        "def random_kmer_from_string(string, profile, k):\n",
        "  \n",
        "  '''\n",
        "  \n",
        "  Input: string of DNA, pre-made profile and kmer length (k)\n",
        "  Output: A random outcome of a kmer from the string\n",
        "  \n",
        "  The functionality is actually simpler than it seems. Given a string we are getting a random kmer from it. \n",
        "  Probabilities are based on a previously made profile\n",
        "  \n",
        "  '''\n",
        "\n",
        "  t = len(string)\n",
        "  probabilities = {}\n",
        "  for i in range(0,t-k+1):\n",
        "      probabilities[string[i:i+k]] = Pr(string[i:i+k], profile)\n",
        "      probabilities = Normalize(probabilities)\n",
        "  return random_dice(probabilities)\n",
        "\n",
        "\n",
        "def gibbs_sampling(Dna, k, N ):\n",
        "  \n",
        "  '''\n",
        "  Input: Set of DNA strings, k mer length, and N steps for iteration\n",
        "  Output: Best scored motifs with their score from the random sampling\n",
        "  \n",
        "  This function is slightly different from our random_greedy_algorithm and its nuances are easier explained part by part as a comparison to that function. Shown below.\n",
        "  '''\n",
        "  \n",
        "  t = len(Dna)\n",
        "  cur = rand_motif_from_DNAset(Dna, k)\n",
        "  best_score_motifs = cur\n",
        "  best_score = motif_scoring(best_score_motifs) # Much like our greedy algorithm and random greedy algorithm, we start by filling up a base set of motifs to call best and compare to. These are randomly selected.\n",
        "  \n",
        "  for iteration in range(N): #We want to iterate this N times so we can gradually approach a good approximation and achieve convergence.\n",
        "    \n",
        "    i = random.randint(0, t-1) #Randomly generate a int in the range of our Dna length. The ith string will be our randomly removed and replaced string.\n",
        "    Profile = nuc_counter_profile(cur[:i] + cur[i+1:]) #Gibbs sampling relies on removing a random string from the list to be ignored or used at a later iteration. So we create a profile with all but the ith string.\n",
        "    \n",
        "    Probabilities = [] #Records all the probabilities of our previously made profile.\n",
        "    for j in range(len(Dna[i])-k+1):\n",
        "      Probabilities.append(Pr(Dna[i][j:j+k], Profile))\n",
        "      \n",
        "    rand_roll = random_outcome_generator(Probabilities) #Our 'dice' now rolls itself based on our found probabilities and gives us a random outcome to use.\n",
        "    cur[i] = Dna[i][rand_roll:rand_roll+k] #Our previously removed ith position is not replaced by\n",
        "    cur_score = motif_scoring(cur) #From this point onwards its more or less the same with our previous algorithms. We score everything, compare it to the previous iterations score and replace it if its better.\n",
        "    if cur_score < best_score: #This continues until improvement stops and we see our 'final' form.\n",
        "      best_score_motifs = cur[:]\n",
        "      best_score = cur_score\n",
        "  return (best_score_motifs, best_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Eh5rNKwN6VA",
        "colab_type": "code",
        "outputId": "d3313f09-1e65-4c87-a718-bd509e6e36db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#A brief comparison of the two main methods here. Look! Their results are somewhat similar!\n",
        "print(random_greedy_algorithm(sample_dna_list, 4))\n",
        "print(gibbs_sampling(sample_dna_list, 4, 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CGGG', 'CGGT', 'CGGG', 'TGGG']\n",
            "(['CGGG', 'CCGG', 'CGGG', 'TGGG'], 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "for4ESCvO98s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Theres two key main algorithms in this section, the rest of the functions simply helpy build them.\n",
        "The first is random_greedy_algorithm. It is not quite as 'greedy' as our first greedy algorithm but it shares many similarities in its code and how it iterates. The main difference is where in the greedy algorithm we used the first kmer from each dna string as a starting motif matrix, here we are *randomly generating* our basis motif matrix. Since we can run this random algorithm as many times as we want, theres a chance of even hitting just one of the right kmers on to start. Which will gradually steer us on the right path towards convergence. However this is not optimal, and random_greedy_algorithm can replace many if not all strings in a motif iteration on one iteration, it may replace strings we want to keep.\n",
        "\n",
        "Gibbs sampling on the other hand which is the 'capstone function' of this entire project, removes only ONE string with each iteration and can choose to toss it or keep it later on based on how the scoring performs. \n",
        "Gibbs sampling starts off the same as random_greedy_algorithm by selecting its first few kmers randomly but makes two more random choices in each iteration. It randomly selects an integer in the range of our DNA length and uses that as a cursor to randomly select a kmer to remove from our motifs. So instead of creating more motifs via the new profile and same DNA strand (motif_creation_double_matrix function) and constantly plugging the new result into that same function to generate an 'improved' matrix, it randomly selects things to generate a new motif in hopes that it is better. \n",
        "\n",
        "**Issues/Evaluation:** The advantages of these Monte Carlo randomized algorithms is that while it may not give us the exact solutions, they can be run many times to quickly help us reach an approximate one. However if you want an analytic solution this can be a problem. \n",
        "Not only this, it can converge on a local optimum, which is essnetially a set of solutions that is optimal with a specific set of data. As opposed to a global optimum which can be generalized to a wider range of contexts. High generalization is especially important for machine learning models."
      ]
    }
  ]
}